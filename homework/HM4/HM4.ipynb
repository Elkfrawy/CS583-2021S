{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 4: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Ayman Elkfrawy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    result = numpy.zeros((len(y), num_class))\n",
    "    for i, y_value in enumerate(y):\n",
    "      result[i, y_value] = 1.0\n",
    "    return result\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 552,874\n",
      "Trainable params: 551,722\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    # model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    # model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    # model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    learning_rate = 1E-3 # to be tuned!\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 211s - loss: 1.4019 - acc: 0.4938 - val_loss: 1.3377 - val_acc: 0.5444\n",
      "Epoch 2/50\n",
      " - 66s - loss: 1.0131 - acc: 0.6398 - val_loss: 1.0755 - val_acc: 0.6442\n",
      "Epoch 3/50\n",
      " - 65s - loss: 0.8788 - acc: 0.6890 - val_loss: 1.0191 - val_acc: 0.6561\n",
      "Epoch 4/50\n",
      " - 54s - loss: 0.7995 - acc: 0.7210 - val_loss: 0.8971 - val_acc: 0.6965\n",
      "Epoch 5/50\n",
      " - 53s - loss: 0.7402 - acc: 0.7406 - val_loss: 0.9292 - val_acc: 0.7095\n",
      "Epoch 6/50\n",
      " - 52s - loss: 0.6927 - acc: 0.7582 - val_loss: 0.8710 - val_acc: 0.7223\n",
      "Epoch 7/50\n",
      " - 51s - loss: 0.6566 - acc: 0.7708 - val_loss: 0.6745 - val_acc: 0.7630\n",
      "Epoch 8/50\n",
      " - 53s - loss: 0.6254 - acc: 0.7836 - val_loss: 0.7168 - val_acc: 0.7562\n",
      "Epoch 9/50\n",
      " - 52s - loss: 0.6059 - acc: 0.7890 - val_loss: 0.8186 - val_acc: 0.7428\n",
      "Epoch 10/50\n",
      " - 52s - loss: 0.5816 - acc: 0.7995 - val_loss: 0.5779 - val_acc: 0.8013\n",
      "Epoch 11/50\n",
      " - 51s - loss: 0.5624 - acc: 0.8045 - val_loss: 0.6352 - val_acc: 0.7942\n",
      "Epoch 12/50\n",
      " - 101s - loss: 0.5435 - acc: 0.8114 - val_loss: 0.8079 - val_acc: 0.7338\n",
      "Epoch 13/50\n",
      " - 51s - loss: 0.5269 - acc: 0.8192 - val_loss: 0.6855 - val_acc: 0.7760\n",
      "Epoch 14/50\n",
      " - 51s - loss: 0.5185 - acc: 0.8218 - val_loss: 1.1620 - val_acc: 0.6784\n",
      "Epoch 15/50\n",
      " - 51s - loss: 0.5030 - acc: 0.8243 - val_loss: 0.7183 - val_acc: 0.7807\n",
      "Epoch 16/50\n",
      " - 52s - loss: 0.4918 - acc: 0.8314 - val_loss: 0.7303 - val_acc: 0.7694\n",
      "Epoch 17/50\n",
      " - 52s - loss: 0.4794 - acc: 0.8350 - val_loss: 0.5629 - val_acc: 0.8133\n",
      "Epoch 18/50\n",
      " - 53s - loss: 0.4687 - acc: 0.8403 - val_loss: 0.5867 - val_acc: 0.8086\n",
      "Epoch 19/50\n",
      " - 51s - loss: 0.4625 - acc: 0.8410 - val_loss: 0.5522 - val_acc: 0.8281\n",
      "Epoch 20/50\n",
      " - 60s - loss: 0.4470 - acc: 0.8469 - val_loss: 0.6198 - val_acc: 0.8125\n",
      "Epoch 21/50\n",
      " - 217s - loss: 0.4409 - acc: 0.8475 - val_loss: 0.7253 - val_acc: 0.7968\n",
      "Epoch 22/50\n",
      " - 64s - loss: 0.4402 - acc: 0.8483 - val_loss: 0.6011 - val_acc: 0.8210\n",
      "Epoch 23/50\n",
      " - 53s - loss: 0.4268 - acc: 0.8539 - val_loss: 0.5470 - val_acc: 0.8342\n",
      "Epoch 24/50\n",
      " - 51s - loss: 0.4213 - acc: 0.8565 - val_loss: 0.4716 - val_acc: 0.8457\n",
      "Epoch 25/50\n",
      " - 52s - loss: 0.4215 - acc: 0.8573 - val_loss: 0.4680 - val_acc: 0.8438\n",
      "Epoch 26/50\n",
      " - 52s - loss: 0.4074 - acc: 0.8611 - val_loss: 0.4982 - val_acc: 0.8339\n",
      "Epoch 27/50\n",
      " - 51s - loss: 0.4019 - acc: 0.8624 - val_loss: 0.6308 - val_acc: 0.8008\n",
      "Epoch 28/50\n",
      " - 52s - loss: 0.3967 - acc: 0.8659 - val_loss: 0.4986 - val_acc: 0.8408\n",
      "Epoch 29/50\n",
      " - 51s - loss: 0.3983 - acc: 0.8633 - val_loss: 0.5298 - val_acc: 0.8394\n",
      "Epoch 30/50\n",
      " - 51s - loss: 0.3907 - acc: 0.8651 - val_loss: 0.6923 - val_acc: 0.7888\n",
      "Epoch 31/50\n",
      " - 51s - loss: 0.3838 - acc: 0.8694 - val_loss: 0.5594 - val_acc: 0.8301\n",
      "Epoch 32/50\n",
      " - 52s - loss: 0.3874 - acc: 0.8683 - val_loss: 0.5125 - val_acc: 0.8425\n",
      "Epoch 33/50\n",
      " - 106s - loss: 0.3745 - acc: 0.8715 - val_loss: 0.6326 - val_acc: 0.8230\n",
      "Epoch 34/50\n",
      " - 50s - loss: 0.3713 - acc: 0.8717 - val_loss: 0.5622 - val_acc: 0.8212\n",
      "Epoch 35/50\n",
      " - 51s - loss: 0.3697 - acc: 0.8736 - val_loss: 0.5591 - val_acc: 0.8408\n",
      "Epoch 36/50\n",
      " - 51s - loss: 0.3703 - acc: 0.8750 - val_loss: 0.4243 - val_acc: 0.8634\n",
      "Epoch 37/50\n",
      " - 52s - loss: 0.3600 - acc: 0.8777 - val_loss: 0.6120 - val_acc: 0.8215\n",
      "Epoch 38/50\n",
      " - 51s - loss: 0.3549 - acc: 0.8783 - val_loss: 0.7026 - val_acc: 0.8085\n",
      "Epoch 39/50\n",
      " - 51s - loss: 0.3515 - acc: 0.8773 - val_loss: 0.5224 - val_acc: 0.8452\n",
      "Epoch 40/50\n",
      " - 54s - loss: 0.3511 - acc: 0.8800 - val_loss: 0.4959 - val_acc: 0.8518\n",
      "Epoch 41/50\n",
      " - 144s - loss: 0.3470 - acc: 0.8827 - val_loss: 0.6352 - val_acc: 0.8238\n",
      "Epoch 42/50\n",
      " - 50s - loss: 0.3478 - acc: 0.8810 - val_loss: 0.4714 - val_acc: 0.8477\n",
      "Epoch 43/50\n",
      " - 50s - loss: 0.3419 - acc: 0.8841 - val_loss: 0.4621 - val_acc: 0.8623\n",
      "Epoch 44/50\n",
      " - 51s - loss: 0.3380 - acc: 0.8824 - val_loss: 0.7565 - val_acc: 0.8063\n",
      "Epoch 45/50\n",
      " - 51s - loss: 0.3307 - acc: 0.8881 - val_loss: 0.6689 - val_acc: 0.8121\n",
      "Epoch 46/50\n",
      " - 51s - loss: 0.3366 - acc: 0.8834 - val_loss: 0.4754 - val_acc: 0.8551\n",
      "Epoch 47/50\n",
      " - 51s - loss: 0.3287 - acc: 0.8862 - val_loss: 0.4416 - val_acc: 0.8626\n",
      "Epoch 48/50\n",
      " - 117s - loss: 0.3204 - acc: 0.8902 - val_loss: 0.3918 - val_acc: 0.8811\n",
      "Epoch 49/50\n",
      " - 124s - loss: 0.3202 - acc: 0.8908 - val_loss: 0.4687 - val_acc: 0.8624\n",
      "Epoch 50/50\n",
      " - 51s - loss: 0.3229 - acc: 0.8895 - val_loss: 0.4455 - val_acc: 0.8609\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    # shear_range=0.2,\n",
    "    # zoom_range=0.5,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "train_datagen.fit(x_tr)\n",
    "\n",
    "batch_size = 64\n",
    "train_gen = train_datagen.flow(x_tr, y_tr, batch_size=batch_size)\n",
    "\n",
    "# for sample in train_gen:\n",
    "#     print(sample.shape)\n",
    "\n",
    "# validation_dataget = ImageDataGenerator()\n",
    "# validation_gen = validation_dataget.flow(x_val, y_val)\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=int(x_tr.shape[0]/batch_size), epochs=50,\n",
    "                              validation_data=(x_val, y_val), verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 552,874\n",
      "Trainable params: 551,722\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 57s - loss: 1.3433 - acc: 0.5154\n",
      "Epoch 2/50\n",
      " - 55s - loss: 0.9598 - acc: 0.6602\n",
      "Epoch 3/50\n",
      " - 55s - loss: 0.8414 - acc: 0.7067\n",
      "Epoch 4/50\n",
      " - 55s - loss: 0.7605 - acc: 0.7317\n",
      "Epoch 5/50\n",
      " - 55s - loss: 0.7120 - acc: 0.7527\n",
      "Epoch 6/50\n",
      " - 55s - loss: 0.6625 - acc: 0.7683\n",
      "Epoch 7/50\n",
      " - 55s - loss: 0.6336 - acc: 0.7803\n",
      "Epoch 8/50\n",
      " - 55s - loss: 0.6077 - acc: 0.7908\n",
      "Epoch 9/50\n",
      " - 52s - loss: 0.5826 - acc: 0.7995\n",
      "Epoch 10/50\n",
      " - 50s - loss: 0.5613 - acc: 0.8066\n",
      "Epoch 11/50\n",
      " - 51s - loss: 0.5470 - acc: 0.8105\n",
      "Epoch 12/50\n",
      " - 51s - loss: 0.5279 - acc: 0.8204\n",
      "Epoch 13/50\n",
      " - 51s - loss: 0.5161 - acc: 0.8238\n",
      "Epoch 14/50\n",
      " - 51s - loss: 0.5021 - acc: 0.8291\n",
      "Epoch 15/50\n",
      " - 51s - loss: 0.4875 - acc: 0.8319\n",
      "Epoch 16/50\n",
      " - 51s - loss: 0.4771 - acc: 0.8362\n",
      "Epoch 17/50\n",
      " - 51s - loss: 0.4686 - acc: 0.8401\n",
      "Epoch 18/50\n",
      " - 51s - loss: 0.4576 - acc: 0.8426\n",
      "Epoch 19/50\n",
      " - 51s - loss: 0.4490 - acc: 0.8484\n",
      "Epoch 20/50\n",
      " - 51s - loss: 0.4443 - acc: 0.8477\n",
      "Epoch 21/50\n",
      " - 51s - loss: 0.4371 - acc: 0.8512\n",
      "Epoch 22/50\n",
      " - 53s - loss: 0.4310 - acc: 0.8543\n",
      "Epoch 23/50\n",
      " - 51s - loss: 0.4239 - acc: 0.8558\n",
      "Epoch 24/50\n",
      " - 51s - loss: 0.4179 - acc: 0.8568\n",
      "Epoch 25/50\n",
      " - 51s - loss: 0.4141 - acc: 0.8590\n",
      "Epoch 26/50\n",
      " - 51s - loss: 0.4045 - acc: 0.8622\n",
      "Epoch 27/50\n",
      " - 51s - loss: 0.3980 - acc: 0.8650\n",
      "Epoch 28/50\n",
      " - 52s - loss: 0.3938 - acc: 0.8661\n",
      "Epoch 29/50\n",
      " - 52s - loss: 0.3908 - acc: 0.8660\n",
      "Epoch 30/50\n",
      " - 51s - loss: 0.3821 - acc: 0.8703\n",
      "Epoch 31/50\n",
      " - 51s - loss: 0.3820 - acc: 0.8705\n",
      "Epoch 32/50\n",
      " - 51s - loss: 0.3773 - acc: 0.8714\n",
      "Epoch 33/50\n",
      " - 51s - loss: 0.3744 - acc: 0.8713\n",
      "Epoch 34/50\n",
      " - 51s - loss: 0.3671 - acc: 0.8745\n",
      "Epoch 35/50\n",
      " - 51s - loss: 0.3642 - acc: 0.8760\n",
      "Epoch 36/50\n",
      " - 51s - loss: 0.3615 - acc: 0.8780\n",
      "Epoch 37/50\n",
      " - 51s - loss: 0.3610 - acc: 0.8776\n",
      "Epoch 38/50\n",
      " - 51s - loss: 0.3509 - acc: 0.8799\n",
      "Epoch 39/50\n",
      " - 51s - loss: 0.3480 - acc: 0.8815\n",
      "Epoch 40/50\n",
      " - 52s - loss: 0.3468 - acc: 0.8814\n",
      "Epoch 41/50\n",
      " - 51s - loss: 0.3410 - acc: 0.8839\n",
      "Epoch 42/50\n",
      " - 51s - loss: 0.3492 - acc: 0.8814\n",
      "Epoch 43/50\n",
      " - 51s - loss: 0.3378 - acc: 0.8840\n",
      "Epoch 44/50\n",
      " - 51s - loss: 0.3368 - acc: 0.8848\n",
      "Epoch 45/50\n",
      " - 51s - loss: 0.3381 - acc: 0.8843\n",
      "Epoch 46/50\n",
      " - 51s - loss: 0.3332 - acc: 0.8857\n",
      "Epoch 47/50\n",
      " - 51s - loss: 0.3262 - acc: 0.8883\n",
      "Epoch 48/50\n",
      " - 51s - loss: 0.3244 - acc: 0.8901\n",
      "Epoch 49/50\n",
      " - 51s - loss: 0.3281 - acc: 0.8894\n",
      "Epoch 50/50\n",
      " - 51s - loss: 0.3208 - acc: 0.8893\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    # shear_range=0.2,\n",
    "    # zoom_range=0.5,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "batch_size = 64\n",
    "train_gen = train_datagen.flow(x_train, y_train_vec, batch_size=batch_size)\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=int(x_train.shape[0]/batch_size), epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.5388658176898956\n",
      "accuracy = 0.8544999957084656\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec, verbose=0)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-d16f93cb",
   "language": "python",
   "display_name": "PyCharm (my_project)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}